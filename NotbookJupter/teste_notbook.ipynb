{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import sounddevice as sd\n",
    "import IPython\n",
    "\n",
    "# Carregando o dataset\n",
    "name_dataset = 'google/fleurs'\n",
    "lingua_dataset = 'pt_br'\n",
    "# Carregando Dados do dataset e convertendo para streaming\n",
    "dados = load_dataset(name_dataset, name=lingua_dataset, split='train' , streaming=True)\n",
    "\n",
    "# Criando o Modelo de Classificação\n",
    "model = 'sanchit-gandhi/whisper-medium-fleurs-lang-id'\n",
    "\n",
    "classificador = pipeline('audio-classification', model=model)\n",
    "\n",
    "for linha in dados.take(5):\n",
    "    predicao = classificador(linha['audio']['array'])\n",
    "    #print(predicao)    \n",
    "\n",
    "# Captura de audio   \n",
    "duracao = 10 # em segundos\n",
    "taxa_amostragem = 16000 # amostras por segundo\n",
    "tamanho_vetor = int(duracao * taxa_amostragem) # cantidade de amostras\n",
    "\n",
    "# Gravacão de audio\n",
    "gravacao = sd.rec(tamanho_vetor, samplerate=taxa_amostragem, channels=1)\n",
    "sd.wait()\n",
    "print(gravacao)\n",
    "gravacao = gravacao.ravel()\n",
    "print(gravacao.shape) # gravacao.shape\n",
    "\n",
    "#Display\n",
    "IPython.display.display(IPython.display.Audio(data=gravacao, rate=taxa_amostragem)) \n",
    "\n",
    "# Detectando o idioma\n",
    "classificador(gravacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import sounddevice as sd\n",
    "import IPython\n",
    "\n",
    "# Carregando o dataset\n",
    "name_dataset = 'google/fleurs'\n",
    "\n",
    "'''\n",
    "# Idioma do dataset\n",
    "lingua_dataset = 'en_us'\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Carregando Dados do dataset e convertendo para streaming\n",
    "dados = load_dataset(name_dataset, name=lingua_dataset, split='train' , streaming=True)\n",
    "\n",
    "# Criando o Modelo de Classificação\n",
    "model = 'sanchit-gandhi/whisper-medium-fleurs-lang-id'\n",
    "\n",
    "classificador = pipeline('audio-classification', model=model)\n",
    "'''\n",
    "for linha in dados.take(5):\n",
    "    predicao = classificador(linha['audio']['array'])\n",
    "    #print(predicao) \n",
    "'''\n",
    " \n",
    " # Captura de audio   \n",
    "duracao = 10 # em segundos\n",
    "taxa_amostragem = 16000 # amostras por segundo\n",
    "tamanho_vetor = int(duracao * taxa_amostragem) # cantidade de amostras\n",
    "\n",
    "# Gravacão de audio\n",
    "gravacao = sd.rec(tamanho_vetor, samplerate=taxa_amostragem, channels=1)\n",
    "\n",
    "sd.wait()\n",
    "\n",
    "print(gravacao)\n",
    "\n",
    "gravacao = gravacao.ravel()\n",
    "\n",
    "print(gravacao.shape) # gravacao.shape\n",
    "\n",
    "IPython.display.display(IPython.display.Audio(data=gravacao, rate=taxa_amostragem))\n",
    "\n",
    "classificador(gravacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import IPython\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from IPython.display import display\n",
    "# Carregando o dataset\n",
    "name_dataset = 'google/fleurs'\n",
    "\n",
    "# Idioma do dataset\n",
    "lingua_dataset = 'pt_br'\n",
    "\n",
    "# Carregando Dados do dataset e convertendo para streaming\n",
    "dados = load_dataset(name_dataset, name=lingua_dataset, split='train' , streaming=True)\n",
    "\n",
    "\n",
    "# Modelo de Classificação\n",
    "model = 'audeering/wav2vec2-large-robust-24-ft-age-gender'\n",
    "classification = pipeline('audio-classification', model=model)\n",
    "\n",
    "for linha in dados.take(5):\n",
    "    audio = linha['audio']\n",
    "    prediction = classification(audio.copy())\n",
    "    print(prediction)    \n",
    "    display(IPython.display.Audio(data=audio['array'], rate=audio['sampling_rate']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "from transformers import pipeline\n",
    "\n",
    "name_dataset = 'PolyAI/minds14'\n",
    "\n",
    "language_dataset = 'pt-PT'\n",
    "\n",
    "dades = load_dataset(name_dataset, name=language_dataset, split='train[:10]' )\n",
    "\n",
    "for line in dades:\n",
    "    dades_song = line['audio']['array']\n",
    "    sampling_rate = line['audio']['sampling_rate']\n",
    "    \n",
    "    #display(IPython.display.Audio(data=dades_song, rate=sampling_rate))\n",
    "    \n",
    "# Modelo de transcrição de audio\n",
    "\n",
    "\n",
    "model = 'openai/whisper-medium'\n",
    "\n",
    "\n",
    "speech_recognizer = pipeline('automatic-speech-recognition', model=model)\n",
    "\n",
    "speech_recognizer(dades[0]['audio'])\n",
    "\n",
    "print(speech_recognizer(dades[0]['audio']))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import time\n",
    "import IPython\n",
    "\n",
    "\n",
    "# Modelo\n",
    "model = 'facebook/mms-tts-por'\n",
    "reader = pipeline('text-to-speech', model=model)\n",
    "\n",
    "text = 'Olá, meu nome é Guilherme e estou aprendendo Python'\n",
    "\n",
    "speaks = reader(text)\n",
    "\n",
    "# temporizador de execução\n",
    "start = time.time()\n",
    "speaks = reader(text)\n",
    "end = time.time()\n",
    "print(f'levou {end - start:2f} segundos para gerar o audio')\n",
    "\n",
    "IPython.display.Audio(data= speaks['audio'], rate= speaks['sampling_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import time\n",
    "import IPython\n",
    "\n",
    "# Modelo\n",
    "model = 'suno/bark-small'\n",
    "reader = pipeline('text-to-speech', model=model, forward_params={'max_new_tokens': 50})\n",
    "\n",
    "# Texto para falar\n",
    "text = 'Olá, meu nome é Guilherme e estou aprendendo Python'\n",
    "speaks = reader(text)\n",
    "\n",
    "# temporizador de execução\n",
    "start = time.time()\n",
    "speaks = reader(text)\n",
    "end = time.time()\n",
    "print(f'levou {end - start} segundos para gerar o audio')\n",
    "\n",
    "IPython.display.Audio(data= speaks['audio'], rate= speaks['sampling_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import time\n",
    "import IPython\n",
    "import torch\n",
    "\n",
    "# Verificar se GPU esta disponivel\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# Modelo\n",
    "model = 'suno/bark-small'\n",
    "reader = pipeline('text-to-speech', model=model,\n",
    "model_kwargs={'torch_dtype': torch.bfloat16},\n",
    "attn_implementation={\"flash_attention_2\"},\n",
    "forward_params={'max_new_tokens': 50})\n",
    "\n",
    "# Move o modelo para a GPU \n",
    "reader.model = reader.model.to(device)\n",
    "reader.model = reader.model.to_bettertransformer()\n",
    "reader.model.enable_cpu_offload()\n",
    "\n",
    "# Texto para falar\n",
    "text = 'Olá, meu nome é Guilherme e estou aprendendo Python'\n",
    "speaks = reader(text)\n",
    "\n",
    "# temporizador de execução\n",
    "start = time.time()\n",
    "speaks = reader(text)\n",
    "end = time.time()\n",
    "print(f'levou {end - start} segundos para gerar o audio')\n",
    "\n",
    "# Display audio\n",
    "IPython.display.Audio(data= speaks['audio'], rate= speaks['sampling_rate'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AGENTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

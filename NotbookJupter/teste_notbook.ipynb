{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import sounddevice as sd\n",
    "import IPython\n",
    "\n",
    "# Carregando o dataset\n",
    "name_dataset = 'google/fleurs'\n",
    "lingua_dataset = 'pt_br'\n",
    "# Carregando Dados do dataset e convertendo para streaming\n",
    "dados = load_dataset(name_dataset, name=lingua_dataset, split='train' , streaming=True)\n",
    "\n",
    "# Criando o Modelo de Classificação\n",
    "model = 'sanchit-gandhi/whisper-medium-fleurs-lang-id'\n",
    "\n",
    "classificador = pipeline('audio-classification', model=model)\n",
    "\n",
    "for linha in dados.take(5):\n",
    "    predicao = classificador(linha['audio']['array'])\n",
    "    #print(predicao)    \n",
    "\n",
    "# Captura de audio   \n",
    "duracao = 10 # em segundos\n",
    "taxa_amostragem = 16000 # amostras por segundo\n",
    "tamanho_vetor = int(duracao * taxa_amostragem) # cantidade de amostras\n",
    "\n",
    "# Gravacão de audio\n",
    "gravacao = sd.rec(tamanho_vetor, samplerate=taxa_amostragem, channels=1)\n",
    "sd.wait()\n",
    "print(gravacao)\n",
    "gravacao = gravacao.ravel()\n",
    "print(gravacao.shape) # gravacao.shape\n",
    "\n",
    "#Display\n",
    "IPython.display.display(IPython.display.Audio(data=gravacao, rate=taxa_amostragem)) \n",
    "\n",
    "# Detectando o idioma\n",
    "classificador(gravacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "import sounddevice as sd\n",
    "import IPython\n",
    "\n",
    "# Carregando o dataset\n",
    "name_dataset = 'google/fleurs'\n",
    "\n",
    "'''\n",
    "# Idioma do dataset\n",
    "lingua_dataset = 'en_us'\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Carregando Dados do dataset e convertendo para streaming\n",
    "dados = load_dataset(name_dataset, name=lingua_dataset, split='train' , streaming=True)\n",
    "\n",
    "# Criando o Modelo de Classificação\n",
    "model = 'sanchit-gandhi/whisper-medium-fleurs-lang-id'\n",
    "\n",
    "classificador = pipeline('audio-classification', model=model)\n",
    "'''\n",
    "for linha in dados.take(5):\n",
    "    predicao = classificador(linha['audio']['array'])\n",
    "    #print(predicao) \n",
    "'''\n",
    " \n",
    " # Captura de audio   \n",
    "duracao = 10 # em segundos\n",
    "taxa_amostragem = 16000 # amostras por segundo\n",
    "tamanho_vetor = int(duracao * taxa_amostragem) # cantidade de amostras\n",
    "\n",
    "# Gravacão de audio\n",
    "gravacao = sd.rec(tamanho_vetor, samplerate=taxa_amostragem, channels=1)\n",
    "\n",
    "sd.wait()\n",
    "\n",
    "print(gravacao)\n",
    "\n",
    "gravacao = gravacao.ravel()\n",
    "\n",
    "print(gravacao.shape) # gravacao.shape\n",
    "\n",
    "IPython.display.display(IPython.display.Audio(data=gravacao, rate=taxa_amostragem))\n",
    "\n",
    "classificador(gravacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import IPython\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from IPython.display import display\n",
    "# Carregando o dataset\n",
    "name_dataset = 'google/fleurs'\n",
    "\n",
    "# Idioma do dataset\n",
    "lingua_dataset = 'pt_br'\n",
    "\n",
    "# Carregando Dados do dataset e convertendo para streaming\n",
    "dados = load_dataset(name_dataset, name=lingua_dataset, split='train' , streaming=True)\n",
    "\n",
    "\n",
    "# Modelo de Classificação\n",
    "model = 'audeering/wav2vec2-large-robust-24-ft-age-gender'\n",
    "classification = pipeline('audio-classification', model=model)\n",
    "\n",
    "for linha in dados.take(5):\n",
    "    audio = linha['audio']\n",
    "    prediction = classification(audio.copy())\n",
    "    print(prediction)    \n",
    "    display(IPython.display.Audio(data=audio['array'], rate=audio['sampling_rate']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AGENTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
